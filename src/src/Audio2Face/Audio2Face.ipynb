{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kp8bMNgoSHS3"
   },
   "source": [
    "# LSP Audio to Face\n",
    "## the input audio is ./data/Input/gen_001.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YSL\\Documents\\PyProjects\\LSP\n",
      "opt: Namespace(A2L_GMM_ndim=75, APC_frame_history=0, APC_hidden_size=512, APC_residual=False, APC_rnn_layers=3, FPS=60, LSTM_dropout=0, LSTM_hidden_size=256, LSTM_layers=3, LSTM_output_size=80, LSTM_residual=False, LSTM_sequence_length=60, audioRF_future=0, audioRF_history=60, audio_encoder='APC', batch_size=32, checkpoints_dir='./checkpoints/', dataroot='default_path', dataset_mode='audiovisual', dataset_names='default_name', eval=False, feature_decoder='LSTM', feature_dtype='pts3d', frame_future=18, frame_jump_stride=4, gpu_ids='0', ispts_norm=1, load_epoch='500', loss='L2', max_dataset_size=inf, model='audio2feature', name='Audio2Feature', num_threads=0, only_mouth=1, phase='test', predict_length=1, sample_rate=16000, sequence_length=240, serial_batches=False, suffix='', task='Audio2Feature', time_frame_length=1, use_delta_pts=1, verbose=False)\n",
      "----------------- Options ---------------\n",
      "             A2L_GMM_ndim: 75                            \n",
      "        APC_frame_history: 0                             \n",
      "          APC_hidden_size: 512                           \n",
      "             APC_residual: False                         \n",
      "           APC_rnn_layers: 3                             \n",
      "                      FPS: 60                            \n",
      "             LSTM_dropout: 0                             \n",
      "         LSTM_hidden_size: 256                           \n",
      "              LSTM_layers: 3                             \n",
      "         LSTM_output_size: 80                            \n",
      "            LSTM_residual: False                         \n",
      "     LSTM_sequence_length: 60                            \n",
      "           audioRF_future: 0                             \n",
      "          audioRF_history: 60                            \n",
      "            audio_encoder: APC                           \n",
      "               batch_size: 32                            \n",
      "          checkpoints_dir: ./checkpoints/                \n",
      "                 dataroot: default_path                  \n",
      "             dataset_mode: audiovisual                   \n",
      "            dataset_names: default_name                  \n",
      "                     eval: False                         \n",
      "          feature_decoder: LSTM                          \n",
      "            feature_dtype: pts3d                         \n",
      "             frame_future: 18                            \n",
      "        frame_jump_stride: 4                             \n",
      "                  gpu_ids: 0                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "               ispts_norm: 1                             \n",
      "               load_epoch: 500                           \n",
      "                     loss: L2                            \n",
      "         max_dataset_size: inf                           \n",
      "                    model: audio2feature                 \n",
      "                     name: Audio2Feature                 \n",
      "              num_threads: 0                             \n",
      "               only_mouth: 1                             \n",
      "                    phase: test                          \n",
      "           predict_length: 1                             \n",
      "              sample_rate: 16000                         \n",
      "          sequence_length: 240                           \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                     task: Audio2Feature                 \n",
      "        time_frame_length: 1                             \n",
      "            use_delta_pts: 1                             \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "----------------- Options ---------------\n",
      "          A2H_GMM_ncenter: 1                             \n",
      "             A2H_GMM_ndim: 12                            \n",
      "        A2H_GMM_sigma_min: 0.03                          \n",
      "         A2H_wavenet_cond: True                          \n",
      "A2H_wavenet_cond_channels: 512                           \n",
      "A2H_wavenet_dilation_channels: 128                           \n",
      "A2H_wavenet_input_channels: 12                            \n",
      "  A2H_wavenet_kernel_size: 2                             \n",
      "A2H_wavenet_residual_blocks: 2                             \n",
      "A2H_wavenet_residual_channels: 128                           \n",
      "A2H_wavenet_residual_layers: 7                             \n",
      "A2H_wavenet_skip_channels: 256                           \n",
      "     A2H_wavenet_use_bias: True                          \n",
      "        APC_frame_history: 60                            \n",
      "          APC_hidden_size: 512                           \n",
      "             APC_residual: False                         \n",
      "           APC_rnn_layers: 3                             \n",
      "                      FPS: 60                            \n",
      "           audioRF_future: 0                             \n",
      "          audioRF_history: 60                            \n",
      "            audio_encoder: APC                           \n",
      "            audio_windows: 2                             \n",
      "audiofeature_input_channels: 80                            \n",
      "done               batch_size: 32                            \n",
      "          checkpoints_dir: ./checkpoints/                \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "LLE projection:   0%|          | 0/238 [00:00<?, ?it/s]\n",
      "LLE projection: 100%|██████████| 238/238 [00:00<00:00, 24790.63it/s]\n",
      "\n",
      "generating headpose:   0%|          | 0/104 [00:00<?, ?it/s]\n",
      "generating headpose:   1%|          | 1/104 [00:01<01:48,  1.05s/it]\n",
      "generating headpose:  12%|█▏        | 12/104 [00:01<00:06, 13.88it/s]\n",
      "generating headpose:  22%|██▏       | 23/104 [00:01<00:02, 27.79it/s]\n",
      "generating headpose:  33%|███▎      | 34/104 [00:01<00:01, 41.87it/s]\n",
      "generating headpose:  44%|████▍     | 46/104 [00:01<00:01, 56.79it/s]\n",
      "generating headpose:  56%|█████▌    | 58/104 [00:01<00:00, 69.31it/s]\n",
      "generating headpose:  67%|██████▋   | 70/104 [00:01<00:00, 80.14it/s]\n",
      "generating headpose:  79%|███████▉  | 82/104 [00:01<00:00, 88.31it/s]\n",
      "generating headpose:  89%|████████▉ | 93/104 [00:01<00:00, 93.72it/s]\n",
      "generating headpose: 100%|██████████| 104/104 [00:01<00:00, 52.39it/s]\n",
      "\n",
      "  0%|          | 0/104 [00:00<?, ?it/s]\n",
      "100%|██████████| 104/104 [00:00<00:00, 25741.04it/s]\n",
      "\n",
      "Image2Image translation inference:   0%|          | 0/104 [00:00<?, ?it/s]\n",
      "Image2Image translation inference:   1%|          | 1/104 [00:00<01:06,  1.54it/s]\n",
      "Image2Image translation inference:   3%|▎         | 3/104 [00:00<00:24,  4.14it/s]\n",
      "Image2Image translation inference:   4%|▍         | 4/104 [00:00<00:19,  5.18it/s]\n",
      "Image2Image translation inference:   6%|▌         | 6/104 [00:01<00:14,  6.86it/s]\n",
      "Image2Image translation inference:   8%|▊         | 8/104 [00:01<00:12,  7.95it/s]\n",
      "Image2Image translation inference:  10%|▉         | 10/104 [00:01<00:10,  8.65it/s]\n",
      "Image2Image translation inference:  12%|█▏        | 12/104 [00:01<00:10,  9.13it/s]\n",
      "Image2Image translation inference:  13%|█▎        | 14/104 [00:01<00:09,  9.42it/s]\n",
      "Image2Image translation inference:  14%|█▍        | 15/104 [00:02<00:09,  9.46it/s]\n",
      "Image2Image translation inference:  16%|█▋        | 17/104 [00:02<00:09,  9.63it/s]\n",
      "Image2Image translation inference:  18%|█▊        | 19/104 [00:02<00:08,  9.74it/s]\n",
      "Image2Image translation inference:  20%|██        | 21/104 [00:02<00:08,  9.86it/s]\n",
      "Image2Image translation inference:  22%|██▏       | 23/104 [00:02<00:08,  9.94it/s]\n",
      "Image2Image translation inference:  24%|██▍       | 25/104 [00:03<00:07,  9.95it/s]\n",
      "Image2Image translation inference:  26%|██▌       | 27/104 [00:03<00:07,  9.87it/s]\n",
      "Image2Image translation inference:  28%|██▊       | 29/104 [00:03<00:07,  9.95it/s]\n",
      "Image2Image translation inference:  30%|██▉       | 31/104 [00:03<00:07,  9.96it/s]\n",
      "Image2Image translation inference:  31%|███       | 32/104 [00:03<00:07,  9.96it/s]\n",
      "Image2Image translation inference:  33%|███▎      | 34/104 [00:03<00:06, 10.01it/s]\n",
      "Image2Image translation inference:  35%|███▍      | 36/104 [00:04<00:06, 10.03it/s]\n",
      "Image2Image translation inference:  37%|███▋      | 38/104 [00:04<00:06, 10.02it/s]\n",
      "Image2Image translation inference:  38%|███▊      | 40/104 [00:04<00:06, 10.03it/s]\n",
      "Image2Image translation inference:  40%|████      | 42/104 [00:04<00:06, 10.02it/s]\n",
      "Image2Image translation inference:  42%|████▏     | 44/104 [00:04<00:05, 10.05it/s]\n",
      "Image2Image translation inference:  44%|████▍     | 46/104 [00:05<00:05, 10.02it/s]\n",
      "Image2Image translation inference:  46%|████▌     | 48/104 [00:05<00:05, 10.00it/s]\n",
      "Image2Image translation inference:  48%|████▊     | 50/104 [00:05<00:05,  9.99it/s]\n",
      "Image2Image translation inference:  49%|████▉     | 51/104 [00:05<00:05,  9.98it/s]\n",
      "Image2Image translation inference:  51%|█████     | 53/104 [00:05<00:05, 10.02it/s]\n",
      "Image2Image translation inference:  53%|█████▎    | 55/104 [00:06<00:04,  9.97it/s]\n",
      "Image2Image translation inference:  55%|█████▍    | 57/104 [00:06<00:04, 10.03it/s]\n",
      "Image2Image translation inference:  57%|█████▋    | 59/104 [00:06<00:04, 10.02it/s]\n",
      "Image2Image translation inference:  59%|█████▊    | 61/104 [00:06<00:04,  9.98it/s]\n",
      "Image2Image translation inference:  61%|██████    | 63/104 [00:06<00:04, 10.04it/s]\n",
      "Image2Image translation inference:  62%|██████▎   | 65/104 [00:07<00:03, 10.03it/s]\n",
      "Image2Image translation inference:  64%|██████▍   | 67/104 [00:07<00:03, 10.01it/s]\n",
      "Image2Image translation inference:  66%|██████▋   | 69/104 [00:07<00:03,  9.99it/s]\n",
      "Image2Image translation inference:  68%|██████▊   | 71/104 [00:07<00:03,  9.99it/s]\n",
      "Image2Image translation inference:  70%|███████   | 73/104 [00:07<00:03,  9.95it/s]\n",
      "Image2Image translation inference:  72%|███████▏  | 75/104 [00:08<00:02, 10.02it/s]\n",
      "Image2Image translation inference:  74%|███████▍  | 77/104 [00:08<00:02, 10.02it/s]\n",
      "Image2Image translation inference:  76%|███████▌  | 79/104 [00:08<00:02, 10.01it/s]\n",
      "Image2Image translation inference:  78%|███████▊  | 81/104 [00:08<00:02,  9.98it/s]\n",
      "Image2Image translation inference:  80%|███████▉  | 83/104 [00:08<00:02, 10.01it/s]\n",
      "Image2Image translation inference:  82%|████████▏ | 85/104 [00:09<00:01, 10.01it/s]\n",
      "Image2Image translation inference:  84%|████████▎ | 87/104 [00:09<00:01, 10.01it/s]\n",
      "Image2Image translation inference:  86%|████████▌ | 89/104 [00:09<00:01, 10.01it/s]\n",
      "Image2Image translation inference:  88%|████████▊ | 91/104 [00:09<00:01,  9.98it/s]\n",
      "Image2Image translation inference:  88%|████████▊ | 92/104 [00:09<00:01,  9.97it/s]\n",
      "Image2Image translation inference:  89%|████████▉ | 93/104 [00:09<00:01,  9.94it/s]\n",
      "Image2Image translation inference:  90%|█████████ | 94/104 [00:09<00:01,  9.85it/s]\n",
      "Image2Image translation inference:  91%|█████████▏| 95/104 [00:10<00:00,  9.87it/s]\n",
      "Image2Image translation inference:  92%|█████████▏| 96/104 [00:10<00:00,  9.90it/s]\n",
      "Image2Image translation inference:  93%|█████████▎| 97/104 [00:10<00:00,  9.91it/s]\n",
      "Image2Image translation inference:  94%|█████████▍| 98/104 [00:10<00:00,  9.89it/s]\n",
      "Image2Image translation inference:  95%|█████████▌| 99/104 [00:10<00:00,  9.87it/s]\n",
      "Image2Image translation inference:  96%|█████████▌| 100/104 [00:10<00:00,  9.84it/s]\n",
      "Image2Image translation inference:  97%|█████████▋| 101/104 [00:10<00:00,  9.88it/s]\n",
      "Image2Image translation inference:  98%|█████████▊| 102/104 [00:10<00:00,  9.90it/s]\n",
      "Image2Image translation inference:  99%|█████████▉| 103/104 [00:10<00:00,  9.85it/s]\n",
      "Image2Image translation inference: 100%|██████████| 104/104 [00:10<00:00,  9.87it/s]\n",
      "Image2Image translation inference: 100%|██████████| 104/104 [00:10<00:00,  9.50it/s]\n",
      "\n",
      "writing video:   0%|          | 0/104 [00:00<?, ?it/s]\n",
      "writing video:  15%|█▌        | 16/104 [00:00<00:00, 157.18it/s]\n",
      "writing video:  33%|███▎      | 34/104 [00:00<00:00, 169.76it/s]\n",
      "writing video:  49%|████▉     | 51/104 [00:00<00:00, 168.94it/s]\n",
      "writing video:  65%|██████▌   | 68/104 [00:00<00:00, 166.09it/s]\n",
      "writing video:  83%|████████▎ | 86/104 [00:00<00:00, 170.19it/s]\n",
      "writing video: 100%|██████████| 104/104 [00:00<00:00, 172.26it/s]\n",
      "writing video: 100%|██████████| 104/104 [00:00<00:00, 169.86it/s]ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 9.2.1 (GCC) 20200122\n",
      "  configuration: --disable-static --enable-shared --enable-gpl --enable-version3 --enable-sdl2 --enable-fontconfig --enable-gnutls --enable-iconv --enable-libass --enable-libdav1d --enable-libbluray --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopus --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libtheora --enable-libtwolame --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libzimg --enable-lzma --enable-zlib --enable-gmp --enable-libvidstab --enable-libvorbis --enable-libvo-amrwbenc --enable-libmysofa --enable-libspeex --enable-libxvid --enable-libaom --enable-libmfx --enable-amf --enable-ffnvcodec --enable-cuvid --enable-d3d11va --enable-nvenc --enable-nvdec --enable-dxva2 --enable-avisynth --enable-libopenmpt\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, avi, from './results/May\\gen_001\\tmp.avi':\n",
      "  Metadata:\n",
      "    encoder         : Lavf57.83.100\n",
      "  Duration: 00:00:01.73, start: 0.000000, bitrate: 1865 kb/s\n",
      "    Stream #0:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 512x512 [SAR 1:1 DAR 1:1], 1844 kb/s, 60 fps, 60 tbr, 60 tbn, 60 tbc\n",
      "Guessed Channel Layout for Input Stream #1.0 : mono\n",
      "Input #1, wav, from './results/May\\gen_001\\tmp.wav':\n",
      "  Duration: 00:00:01.73, bitrate: 512 kb/s\n",
      "    Stream #1:0: Audio: pcm_f32le ([3][0][0][0] / 0x0003), 16000 Hz, mono, flt, 512 kb/s\n",
      "Output #0, avi, to './results/May\\gen_001\\gen_001.avi':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf58.29.100\n",
      "    Stream #0:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 512x512 [SAR 1:1 DAR 1:1], q=2-31, 1844 kb/s, 60 fps, 60 tbr, 60 tbn, 60 tbc\n",
      "    Stream #0:1: Audio: pcm_f32le ([3][0][0][0] / 0x0003), 16000 Hz, mono, flt, 512 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "  Stream #1:0 -> #0:1 (copy)\n",
      "Press [q] to stop, [?] for help\n",
      "frame=  104 fps=0.0 q=-1.0 Lsize=     508kB time=00:00:01.73 bitrate=2400.3kbits/s speed=1.73e+03x    \n",
      "video:387kB audio:108kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 2.620404%\n",
      "\n",
      "\n",
      "writing video:   0%|          | 0/104 [00:00<?, ?it/s]\n",
      "writing video:  23%|██▎       | 24/104 [00:00<00:00, 236.95it/s]\n",
      "writing video:  46%|████▌     | 48/104 [00:00<00:00, 225.04it/s]\n",
      "writing video:  68%|██████▊   | 71/104 [00:00<00:00, 226.98it/s]\n",
      "writing video:  90%|█████████ | 94/104 [00:00<00:00, 223.15it/s]\n",
      "writing video: 100%|██████████| 104/104 [00:00<00:00, 226.07it/s]ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 9.2.1 (GCC) 20200122\n",
      "  configuration: --disable-static --enable-shared --enable-gpl --enable-version3 --enable-sdl2 --enable-fontconfig --enable-gnutls --enable-iconv --enable-libass --enable-libdav1d --enable-libbluray --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopus --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libtheora --enable-libtwolame --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libzimg --enable-lzma --enable-zlib --enable-gmp --enable-libvidstab --enable-libvorbis --enable-libvo-amrwbenc --enable-libmysofa --enable-libspeex --enable-libxvid --enable-libaom --enable-libmfx --enable-amf --enable-ffnvcodec --enable-cuvid --enable-d3d11va --enable-nvenc --enable-nvdec --enable-dxva2 --enable-avisynth --enable-libopenmpt\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, avi, from './results/May\\gen_001\\tmp.avi':\n",
      "  Metadata:\n",
      "    encoder         : Lavf57.83.100\n",
      "  Duration: 00:00:01.73, start: 0.000000, bitrate: 3246 kb/s\n",
      "    Stream #0:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 512x512 [SAR 1:1 DAR 1:1], 3239 kb/s, 60 fps, 60 tbr, 60 tbn, 60 tbc\n",
      "Guessed Channel Layout for Input Stream #1.0 : mono\n",
      "Input #1, wav, from './results/May\\gen_001\\tmp.wav':\n",
      "  Duration: 00:00:01.73, bitrate: 512 kb/s\n",
      "    Stream #1:0: Audio: pcm_f32le ([3][0][0][0] / 0x0003), 16000 Hz, mono, flt, 512 kb/s\n",
      "Output #0, avi, to './results/May\\gen_001\\gen_001_feature_maps.avi':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf58.29.100\n",
      "    Stream #0:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 512x512 [SAR 1:1 DAR 1:1], q=2-31, 3239 kb/s, 60 fps, 60 tbr, 60 tbn, 60 tbc\n",
      "    Stream #0:1: Audio: pcm_f32le ([3][0][0][0] / 0x0003), 16000 Hz, mono, flt, 512 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 dataroot: path                          \n",
      "             dataset_mode: audiovisual                   \n",
      "            dataset_names: name                          \n",
      "                     eval: False                         \n",
      "          feature_decoder: WaveNet                       \n",
      "             frame_future: 15                            \n",
      "        frame_jump_stride: 1                             \n",
      "                  gpu_ids: 0                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "               load_epoch: 500                           \n",
      "                     loss: GMM                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: audio2headpose                \n",
      "                     name: Audio2Headpose                \n",
      "              num_threads: 0                             \n",
      "                    phase: test                          \n",
      "           predict_length: 5                             \n",
      "              sample_rate: 16000                         \n",
      "          sequence_length: 240                           \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                     task: Audio2Headpose                \n",
      "        time_frame_length: 1                             \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "------------ Options -------------\n",
      "batch_size: 1\n",
      "checkpoints_dir: ./checkpoints/\n",
      "dataroot: ./data/\n",
      "dataset_mode: face\n",
      "dataset_names: ['name']\n",
      "debug: False\n",
      "display_id: 0\n",
      "display_winsize: 512\n",
      "fineSize: 512\n",
      "fp16: 0\n",
      "gpu_ids: [0]\n",
      "input_nc: 1\n",
      "isH5: 1\n",
      "isMask: 0\n",
      "isTrain: False\n",
      "loadSize: 512\n",
      "load_pretrain: \n",
      "local_rank: 0\n",
      "max_dataset_size: inf\n",
      "model: feature2face\n",
      "n_blocks_E: 3\n",
      "n_downsample_E: 3\n",
      "n_downsample_G: 8\n",
      "name: TestRender\n",
      "ngf: 64\n",
      "ngf_E: 16\n",
      "no_flip: 1\n",
      "num_threads: 0\n",
      "output_nc: 3\n",
      "phase: test\n",
      "resize_or_crop: scaleWidth\n",
      "serial_batches: False\n",
      "suffix: .jpg\n",
      "task: Feature2Face\n",
      "test_dataset_names: ['name']\n",
      "tf_log: True\n",
      "verbose: False\n",
      "-------------- End ----------------\n",
      "---------- Loading Model: APC-------------\n",
      "---------- Loading Model: Audio2Feature -------------\n",
      "initialize network with normal\n",
      "model [Audio2FeatureModel] was created\n",
      "loading the model from ./data/May/checkpoints/Audio2Feature.pkl\n",
      "---------- Networks initialized -------------\n",
      "[Network Audio2Feature] Total number of parameters : 3.064 M\n",
      "-----------------------------------------------\n",
      "---------- Loading Model: Audio2Headpose -------------\n",
      "initialize network with normal\n",
      "model [Audio2HeadposeModel] was created\n",
      "loading the model from ./data/May/checkpoints/Audio2Headpose.pkl\n",
      "---------- Networks initialized -------------\n",
      "[Network Audio2Headpose] Total number of parameters : 4.267 M\n",
      "-----------------------------------------------\n",
      "---------- Loading Model: Feature2Face -------------\n",
      "dataset [FaceDataset] was created\n",
      "---------- Generator networks initialized -------------\n",
      "-------------------------------------------------------\n",
      "initialize network with normal\n",
      "model [Feature2FaceModel] was created\n",
      "loading the model from ./data/May/checkpoints/Feature2Face.pkl\n",
      "---------- Networks initialized -------------\n",
      "[Network Feature2Face_G] Total number of parameters : 121.790 M\n",
      "-----------------------------------------------\n",
      "Processing audio: gen_001 ...\n",
      "1. Computing APC features...\n",
      "2. Manifold projection...\n",
      "3. Audio2Mouth inference...\n",
      "4. Headpose inference...\n",
      "5. Post-processing...\n",
      "6. Image2Image translation & Saving results...\n",
      "Finish!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Stream #1:0 -> #0:1 (copy)\n",
      "Press [q] to stop, [?] for help\n",
      "frame=  104 fps=0.0 q=-1.0 Lsize=     800kB time=00:00:01.73 bitrate=3781.8kbits/s speed= 861x    \n",
      "video:679kB audio:108kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.647044%\n",
      "\n",
      "\n",
      "deleting intermediate images:   0%|          | 0/208 [00:00<?, ?it/s]\n",
      "deleting intermediate images: 100%|██████████| 208/208 [00:00<00:00, 10181.42it/s]\n"
     ]
    }
   ],
   "source": [
    "%cd ../LSP\n",
    "!python demo.py --id May --driving_audio ./data/Input/gen_001.wav --device cuda\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Order Model Deep Fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YSL\\Documents\\PyProjects\\deepFake\\first-order-model\n",
      "CONFIGURE DONE\n"
     ]
    }
   ],
   "source": [
    "%cd ../deepFake/first-order-model\n",
    " \n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from skimage.transform import resize\n",
    "from IPython.display import HTML\n",
    "from IPython.display import Image\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    " \n",
    " \n",
    "def display(source, driving, generated1=None, generated2 = None):\n",
    "    fig = plt.figure(figsize=(8 + 4 * (generated1 is not None) + 4 * (generated2 is not None), 6))\n",
    " \n",
    "    ims = []\n",
    "    for i in range(len(driving)):\n",
    "        cols = [source]\n",
    "        cols.append(driving[i])\n",
    "        if generated1 is not None:\n",
    "            cols.append(generated1[i])\n",
    "        if generated2 is not None:\n",
    "            cols.append(generated2[i])\n",
    "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
    "        plt.axis('off')\n",
    "        ims.append([im])\n",
    " \n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=50, repeat_delay=1000)\n",
    "    plt.close()\n",
    "    return ani\n",
    " \n",
    "Checkpoint = 'vox-cpk.pth' #@param[\"vox-cpk.pth\", \"vox-adv-cpk.pth\"]\n",
    "checkpoint_p = {\n",
    "    \"vox-cpk.pth\": '../content/first-order-motion-model/vox-cpk.pth.tar', \n",
    "    \"vox-adv-cpk.pth\": '../content/first-order-motion-model/vox-adv-cpk.pth.tar'\n",
    "}\n",
    " \n",
    "\n",
    "def show_local_mp4_video(file_name, slowmoFactor, width=640, height=480):\n",
    "  import io\n",
    "  import base64\n",
    "  from IPython.display import HTML\n",
    "  video_encoded = base64.b64encode(io.open(file_name, 'rb').read())\n",
    "  return HTML(data='''\n",
    "                        <script>\n",
    "                          var vid = document.getElementById(\"myVideo\");\n",
    "                          vid.playbackRate = 1/{3};\n",
    "                        </script>\n",
    "                        <video width=\"{0}\" height=\"{1}\" alt=\"test\" id=\"myVideo\" controls>\n",
    "                        <source src=\"data:video/mp4;base64,{2}\" type=\"video/mp4\" />\n",
    "                      </video>'''.format(width, height, video_encoded.decode('ascii'), slowmoFactor))\n",
    "  \n",
    "from demo import load_checkpoints\n",
    "generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml', \n",
    "                            checkpoint_path=str(checkpoint_p[Checkpoint]))\n",
    " \n",
    " \n",
    "from demo import make_animation\n",
    "from skimage import img_as_ubyte\n",
    "# from moviepy.editor import *\n",
    "print(\"CONFIGURE DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The input source image is ../content/source.jpg\n",
    "## The driven video is ../../LSP/results/May/gen_001/gen_001.avi\n",
    "## which is generated before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "id": "HjBaSfAa80Av",
    "outputId": "ab557830-95a9-49a9-821e-298891997aaa",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 9.2.1 (GCC) 20200122\n",
      "  configuration: --disable-static --enable-shared --enable-gpl --enable-version3 --enable-sdl2 --enable-fontconfig --enable-gnutls --enable-iconv --enable-libass --enable-libdav1d --enable-libbluray --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopus --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libtheora --enable-libtwolame --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libzimg --enable-lzma --enable-zlib --enable-gmp --enable-libvidstab --enable-libvorbis --enable-libvo-amrwbenc --enable-libmysofa --enable-libspeex --enable-libxvid --enable-libaom --enable-libmfx --enable-amf --enable-ffnvcodec --enable-cuvid --enable-d3d11va --enable-nvenc --enable-nvdec --enable-dxva2 --enable-avisynth --enable-libopenmpt\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, avi, from '../../LSP/results/May/gen_001/gen_001.avi':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:01.73, start: 0.000000, bitrate: 2400 kb/s\n",
      "    Stream #0:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 512x512 [SAR 1:1 DAR 1:1], 1844 kb/s, 60 fps, 60 tbr, 60 tbn, 60 tbc\n",
      "    Stream #0:1: Audio: pcm_f32le ([3][0][0][0] / 0x0003), 16000 Hz, mono, flt, 512 kb/s\n",
      "[NULL @ 0000023aeece8d40] Unable to find a suitable output format for ''../content/df_audio.mp3''\n",
      "'../content/df_audio.mp3': Invalid argument\n",
      "100%|██████████| 104/104 [00:08<00:00, 12.81it/s]\n"
     ]
    }
   ],
   "source": [
    "Source_Image = '../content/source.jpg' \n",
    "Driving_Video = '../../LSP/results/May/gen_001/gen_001.avi' \n",
    "\n",
    "s_path = str(Source_Image)\n",
    "\n",
    "\n",
    "d_path = str(Driving_Video)\n",
    "\n",
    "\n",
    "source_image = imageio.imread(s_path)\n",
    "reader = imageio.get_reader(d_path)\n",
    "driving_video = []\n",
    "try:\n",
    "    for im in reader:\n",
    "        driving_video.append(im)\n",
    "except RuntimeError:\n",
    "    pass\n",
    "reader.close()\n",
    "# driving_video = imageio.mimread(d_path, memtest=False)\n",
    "\n",
    "#Resize image and video to 256x256\n",
    "source_image = resize(source_image, (256, 256))[..., :3]\n",
    "driving_video = [resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
    "\n",
    "\n",
    "#find the frame_rate of driving video\n",
    "from fractions import Fraction\n",
    "frame_rate_source = !ffprobe -v error -select_streams v -of default=noprint_wrappers=1:nokey=1 -show_entries stream=r_frame_rate $d_path\n",
    "frame_rate_source = float(Fraction(frame_rate_source[0]))\n",
    "\n",
    "\n",
    "# check if video has audio stream\n",
    "audio_ = !ffprobe -i $d_path -show_streams -select_streams a -loglevel error\n",
    "audio_stream = list(audio_)\n",
    "hasAudio = None\n",
    "\n",
    "\n",
    "if len(audio_stream) != 0:\n",
    "  # has audio\n",
    "  hasAudio = True\n",
    "else:\n",
    "  hasAudio = False\n",
    "\n",
    "\n",
    "#save resized img and video\n",
    "t1= imageio.imwrite('../content/resized_source_img.png', source_image)\n",
    "t2 = imageio.mimsave('../content/resized_driving_video.mp4', driving_video , fps = int(frame_rate_source))\n",
    "\n",
    "\n",
    "\n",
    "#extarct audio from driving video\n",
    "if hasAudio:\n",
    "  !ffmpeg -i $d_path '../content/df_audio.mp3'\n",
    "\n",
    "\n",
    "predictions1 = make_animation(source_image, driving_video, generator, kp_detector, relative=True)\n",
    "imageio.mimsave('../output/output.mp4', [img_as_ubyte(frame) for frame in predictions1], fps = int(frame_rate_source))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "first_order_model_demo(Youtube)_new-audioV5_b.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
